import streamlit as st
import yfinance as yf
import feedparser
import requests
import time
from urllib.parse import quote
import google.generativeai as genai

# === é¡µé¢è®¾ç½® ===
st.set_page_config(page_title="ç¾è‚¡å…¨æ™¯AIé›·è¾¾", page_icon="ğŸ“¡", layout="wide")
st.title("ğŸ“¡ ç¾è‚¡å…¨æ™¯AIé›·è¾¾")
st.caption("Powered by Google Gemini 2.5 & Yahoo Finance | å…¨çƒå®è§‚/ç§‘æŠ€/å‘¨æœŸ/é¿é™©")

# === ä¾§è¾¹æ ï¼šé…ç½® ===
with st.sidebar:
    st.header("âš™ï¸ æ§åˆ¶å°")
    api_key = st.text_input("Google API Key", type="password", help="éœ€è¦ Gemini API æƒé™")
    st.info("æç¤ºï¼šç”±äºç›‘æ§æ ‡çš„å¢åŠ åˆ°40+ä¸ªï¼Œå®Œæ•´æ‰«æå¯èƒ½éœ€è¦ 1-2 åˆ†é’Ÿï¼Œè¯·è€å¿ƒç­‰å¾…ã€‚")

# === æ ¸å¿ƒé€»è¾‘ï¼šèµ„äº§åˆ†ç»„æ¸…å• ===
WATCHLIST_GROUPS = {
    "ğŸš€ å¸‚åœºæ€»è§ˆ": {
        "^GSPC":   ["æ ‡æ™®500", "S&P 500 market analysis"],
        "^IXIC":   ["çº³æ–¯è¾¾å…‹", "Nasdaq Composite analysis"],
        "^RUT":    ["ç½—ç´ 2000 (å®ä½“ç»æµ)", "Russell 2000 small cap stocks"],
        "^VIX":    ["VIXææ…ŒæŒ‡æ•°", "CBOE VIX volatility index"],
    },
    "ğŸ‘‘ ç§‘æŠ€ä¸ƒå·¨å¤´": {
        "NVDA":    ["è‹±ä¼Ÿè¾¾", "Nvidia stock news"],
        "MSFT":    ["å¾®è½¯", "Microsoft stock AI"],
        "AAPL":    ["è‹¹æœ", "Apple Inc stock news"],
        "GOOGL":   ["è°·æ­Œ", "Alphabet Google stock"],
        "AMZN":    ["äºšé©¬é€Š", "Amazon stock news"],
        "META":    ["Meta", "Meta Platforms news"],
        "TSLA":    ["ç‰¹æ–¯æ‹‰", "Tesla stock news"],
    },
    "âš™ï¸ ç¡¬æ ¸åŠå¯¼ä½“": {
        "TSM":     ["å°ç§¯ç”µ", "TSMC stock news"],
        "ASML":    ["ASML", "ASML stock lithography"],
        "AVGO":    ["åšé€š", "Broadcom stock news"],
        "AMD":     ["AMD", "AMD stock news"],
        "SMH":     ["åŠå¯¼ä½“ETF", "VanEck Vectors Semiconductor ETF"],
    },
    "ğŸ’° å®è§‚æµåŠ¨æ€§": {
        "^TNX":    ["10å¹´æœŸç¾å€º", "US 10 year treasury yield"],
        "DX-Y.NYB": ["ç¾å…ƒæŒ‡æ•°", "US Dollar index"],
        "JPY=X":   ["ç¾å…ƒå…‘æ—¥å…ƒ", "USD JPY exchange rate"],
        "TLT":     ["20å¹´+ç¾å€º", "iShares 20+ Year Treasury Bond ETF"],
    },
    "ğŸš¨ ä¿¡ç”¨ä¸é¿é™©": {
        "HYG":     ["é«˜æ”¶ç›Šå€º(åƒåœ¾å€º)", "High Yield Corporate Bond ETF default risk"],
        "GLD":     ["é»„é‡‘", "Gold price investing"],
        "BTC-USD": ["æ¯”ç‰¹å¸", "Bitcoin crypto market sentiment"],
    },
    "ğŸ­ å‘¨æœŸä¸é€šèƒ€": {
        "CL=F":    ["åŸæ²¹", "Crude oil price energy"],
        "XLE":     ["èƒ½æºæ¿å—", "US Energy Sector ETF"],
        "XLF":     ["é‡‘èæ¿å—", "US Financials Sector ETF"],
        "CAT":     ["å¡ç‰¹å½¼å‹’", "Caterpillar stock economy"],
    },
    "ğŸ›¡ï¸ é˜²å¾¡æ¿å—": {
        "XLV":     ["åŒ»ç–—å¥åº·", "Health Care Sector ETF"],
        "XLP":     ["å¿…éœ€æ¶ˆè´¹", "Consumer Staples Sector ETF"],
        "WMT":     ["æ²ƒå°”ç›", "Walmart stock consumer"],
    },
    "ğŸ‡¨ğŸ‡³ ä¸­å›½ä¸æ–°å…´": {
        "^HSI":    ["æ’ç”ŸæŒ‡æ•°", "Hang Seng Index Hong Kong"],
        "FXI":     ["ä¸­å›½å¤§ç›˜è‚¡", "China large cap ETF investing"],
        "KWEB":    ["ä¸­å›½äº’è”ç½‘", "China internet ETF tech"],
    }
}

SPECIAL_TOPICS = [
    "US Federal Reserve Powell policy",           # ç¾è”å‚¨
    "Bank of Japan Governor Ueda policy",         # æ—¥æœ¬å¤®è¡Œ
    "Geopolitical tension Middle East Russia",    # åœ°ç¼˜æ”¿æ²»
    "US China trade war tariffs",                 # è´¸æ˜“æˆ˜
    "US inflation CPI PCE data",                  # é€šèƒ€
    "US recession soft landing probability",      # è¡°é€€é¢„æµ‹
    "Artificial Intelligence AI market impact",   # AI å½±å“
    "trump",                                      # ç‰¹æœ—æ™®

]

def get_news(query):
    encoded = quote(query)
    url = f"https://news.google.com/rss/search?q={encoded}&hl=en-US&gl=US&ceid=US:en"
    try:
        headers = {'User-Agent': 'Mozilla/5.0'}
        resp = requests.get(url, timeout=6, headers=headers)
        feed = feedparser.parse(resp.content)
        return [{"title": e.title, "link": e.link} for e in feed.entries[:3]] # é™åˆ¶æ¯æ¡3ä¸ªæ–°é—»ï¼Œé¿å…è¿‡é•¿
    except: return []

def run_analysis():
    if not api_key:
        st.error("âŒ è¯·å…ˆåœ¨å·¦ä¾§è¾“å…¥ API Key")
        return

    genai.configure(api_key=api_key.strip(), transport='rest')
    model = genai.GenerativeModel('gemini-2.5-pro')
    
    # ç•Œé¢åˆå§‹åŒ–
    status_text = st.empty()
    progress_bar = st.progress(0)
    
    # åˆ›å»ºæ ‡ç­¾é¡µ
    tab_names = list(WATCHLIST_GROUPS.keys()) + ["ğŸ” å®è§‚è¯é¢˜"]
    tabs = st.tabs(tab_names)
    
    market_data = ""
    all_news_titles = [] 
    
    # è®¡ç®—æ€»æ­¥æ•°
    total_assets = sum(len(v) for v in WATCHLIST_GROUPS.values())
    total_topics = len(SPECIAL_TOPICS)
    total_steps = total_assets + total_topics
    current_step = 0

    # === 1. åˆ†ç»„æŠ“å–èµ„äº§æ•°æ® ===
    # éå†æ¯ä¸€ä¸ªåˆ†ç»„ï¼ˆå¯¹åº”ä¸€ä¸ªTabï¼‰
    for i, (group_name, items) in enumerate(WATCHLIST_GROUPS.items()):
        with tabs[i]: # åˆ‡æ¢åˆ°å¯¹åº”æ ‡ç­¾é¡µæ˜¾ç¤º
            cols = st.columns(2) # æ¯è¡Œæ˜¾ç¤ºä¸¤ä¸ªå¡ç‰‡ï¼Œæ›´ç´§å‡‘
            col_idx = 0
            
            market_data += f"\n=== ã€{group_name}ã€‘æ¿å—æ•°æ® ===\n"
            
            for ticker, info in items.items():
                status_text.text(f"ğŸ“¡ æ­£åœ¨æ‰«æ: {group_name} - {info[0]}...")
                
                try:
                    # è·å–ä»·æ ¼
                    stock = yf.Ticker(ticker)
                    time.sleep(0.1) # é˜²å°æ§
                    hist = stock.history(period="2d")
                    
                    price_str = "N/A"
                    change_str = ""
                    if len(hist) > 0:
                        last_price = hist['Close'].iloc[-1]
                        price_str = f"{last_price:.2f}"
                        # è®¡ç®—æ¶¨è·Œå¹…
                        if len(hist) > 1:
                            prev_price = hist['Close'].iloc[-2]
                            change = ((last_price - prev_price) / prev_price) * 100
                            emoji = "ğŸ”´" if change < 0 else "ğŸŸ¢"
                            change_str = f"({emoji} {change:+.2f}%)"

                    # è·å–æ–°é—»
                    news = get_news(info[1])
                    
                    # è®°å½•æ•°æ®ç»™ AI
                    market_data += f"[{info[0]}] ä»·æ ¼:{price_str} {change_str}\n"
                    for n in news:
                        market_data += f"   - News: {n['title']}\n"
                        all_news_titles.append(n['title'])
                    
                    # ç•Œé¢å±•ç¤º (ä½¿ç”¨ st.expander)
                    with cols[col_idx % 2].expander(f"{info[0]} {price_str} {change_str}", expanded=False):
                        for n in news:
                            st.write(f"- [{n['title']}]({n['link']})")
                    
                    col_idx += 1

                except Exception as e:
                    # st.warning(f"æ— æ³•è·å– {info[0]}: {e}")
                    pass
                
                current_step += 1
                progress_bar.progress(current_step / total_steps)

    # === 2. æŠ“å–è¯é¢˜ ===
    with tabs[-1]: # æœ€åä¸€ä¸ªæ ‡ç­¾é¡µ
        status_text.text(f"ğŸ“¡ æ­£åœ¨è¿½è¸ªå®è§‚è¯é¢˜...")
        st.caption("åŸºäº Google News çš„å®æ—¶è¯é¢˜è¿½è¸ª")
        
        market_data += f"\n=== ã€å®è§‚è¯é¢˜è¿½è¸ªã€‘ ===\n"
        
        for topic in SPECIAL_TOPICS:
            news = get_news(topic)
            if news:
                market_data += f"Topic: {topic}\n"
                with st.expander(f"ğŸ“Œ {topic}", expanded=True):
                    for n in news:
                        st.write(f"- [{n['title']}]({n['link']})")
                        market_data += f"   - {n['title']}\n"
                        all_news_titles.append(n['title'])
            
            current_step += 1
            progress_bar.progress(current_step / total_steps)

    status_text.text("ğŸ¤– AI æ­£åœ¨åŸºäºå…¨æ™¯æ•°æ®æ’°å†™æ·±åº¦å†…å‚ (çº¦éœ€ 10-20 ç§’)...")
    
    # === 3. AI åˆ†æ ===
    unique_news_titles = "\n".join(list(set(all_news_titles)))
    
    prompt = f"""
    è§’è‰²ï¼šåå°”è¡—é¡¶çº§å®è§‚å¯¹å†²åŸºé‡‘çš„é¦–å¸­ç­–ç•¥å¸ˆ (CIO)ã€‚
    ä»»åŠ¡ï¼šåŸºäºä»¥ä¸‹ã€å…¨æ™¯å¸‚åœºæ•°æ®ã€‘æ’°å†™ä¸€ä»½ã€Šå…¨çƒè·¨èµ„äº§å®æˆ˜å†…å‚ã€‹ã€‚
    
    ä½ éœ€è¦ç»¼åˆåˆ†æï¼šç§‘æŠ€è‚¡åŠ¨èƒ½ã€å®è§‚æµåŠ¨æ€§(ç¾å€º/ç¾å…ƒ/æ—¥å…ƒ)ã€ä¿¡ç”¨é£é™©(é«˜æ”¶ç›Šå€º)ã€ä»¥åŠåœ°ç¼˜ä¸ä¸­å›½èµ„äº§çš„å½±å“ã€‚
    
    --- ğŸ“° åŸå§‹æ–°é—»æ±  (ä¾›æ¦‚æ‹¬) ---
    {unique_news_titles}
    
    --- ğŸ“Š å…¨æ™¯å¸‚åœºæ•°æ® (å«ä»·æ ¼å˜åŠ¨) ---
    {market_data}
    
    --- å†™ä½œè¦æ±‚ ---
    1. **ç»“æ„åŒ–è¾“å‡º**ï¼šè¯·ä¸¥æ ¼æŒ‰ç…§ä¸‹æ–¹ç›®å½•ç»“æ„è¾“å‡ºã€‚
    2. **å»é“¾æ¥åŒ–**ï¼šä¸è¦åŒ…å«ä»»ä½• URLã€‚
    3. **ä¸­æ–‡å†™ä½œ**ï¼šä¸“ä¸šã€çŠ€åˆ©ã€ç®€ç»ƒã€‚
    
    --- æŠ¥å‘Šç›®å½•ç»“æ„ ---
    # ğŸ“° æœ¬æ—¥ç„¦ç‚¹ (Market Focus)
    > (ä»æ–°é—»æ± ä¸­æç‚¼5æ¡æœ€é‡è¦æ–°é—»ï¼Œä¸€å¥è¯æ¦‚æ‹¬ï¼Œå¹¶åœ¨æœ«å°¾æ ‡æ³¨å…¶å¯¹å¸‚åœºæ˜¯[åˆ©å¤š]è¿˜æ˜¯[åˆ©ç©º])

    # 1. ğŸŒ¡ï¸ å¸‚åœºæ¸©åº¦è®¡ (Market Breadth)
    > (åˆ†ææ ‡æ™®vsç½—ç´ ã€ææ…ŒæŒ‡æ•°VIXã€ä»¥åŠæ¯”ç‰¹å¸ã€‚åˆ¤æ–­å½“å‰æ˜¯"å…¨é¢ç‰›å¸‚"ã€"åªæœ‰ç§‘æŠ€è‚¡æ¶¨çš„è™šå‡ç¹è£"è¿˜æ˜¯"é¿é™©æ¨¡å¼"ï¼Ÿ)

    # 2. ğŸ‡¯ğŸ‡µ å®è§‚ä¸æµåŠ¨æ€§ (Liquidity Watch)
    > (é‡ç‚¹åˆ†æç¾å€ºæ”¶ç›Šç‡ã€æ—¥å…ƒæ±‡ç‡ã€ç¾å…ƒæŒ‡æ•°ã€‚æµåŠ¨æ€§æ˜¯åœ¨æ”¶ç´§è¿˜æ˜¯é‡Šæ”¾ï¼Ÿ)

    # 3. ğŸ¤– ç§‘æŠ€ä¸åŠå¯¼ä½“ (Tech & AI)
    > (ç‚¹è¯„ NVDA/MSFT/TSM ç­‰æ ¸å¿ƒç¥¨èµ°åŠ¿ã€‚AI æ³¡æ²«ä¸ä»…æ˜¯ä¿¡ä»°ï¼Œè¿˜è¦çœ‹ä»·æ ¼åŠ¨èƒ½ã€‚)

    # 4. âš ï¸ é£é™©é›·è¾¾ (Risk Monitor)
    > (è§‚å¯Ÿé«˜æ”¶ç›Šå€º HYGã€é»„é‡‘ GLD å’ŒåŸæ²¹ã€‚æ˜¯å¦æœ‰ç»æµè¡°é€€æˆ–é€šèƒ€åå¼¹çš„è¿¹è±¡ï¼Ÿ)

    # 5. ğŸ“ äº¤æ˜“å‘˜ç­–ç•¥ (Actionable Strategy)
    > (ç»™å‡ºå…·ä½“çš„æ“ä½œå»ºè®®ï¼šåšå¤šå“ªä¸ªæ¿å—ï¼Ÿå¯¹å†²ä»€ä¹ˆé£é™©ï¼Ÿå½“å‰ä»“ä½å»ºè®®æ˜¯æ¿€è¿›è¿˜æ˜¯é˜²å¾¡ï¼Ÿ)
    """
    
    try:
        response = model.generate_content(prompt)
        status_text.text("âœ… åˆ†æå®Œæˆï¼")
        st.success("æ·±åº¦åˆ†ææŠ¥å‘Šå·²ç”Ÿæˆ")
        st.markdown("---")
        st.markdown(response.text)
    except Exception as e:
        st.error(f"AI ç”Ÿæˆå¤±è´¥: {e}")

# === å¯åŠ¨æŒ‰é’® ===
if st.button("ğŸš€ å¯åŠ¨å…¨æ™¯é›·è¾¾ (Full Scan)", type="primary"):
    run_analysis()