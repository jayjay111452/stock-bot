import streamlit as st
import yfinance as yf
import feedparser
import requests
import time
from urllib.parse import quote
import google.generativeai as genai

# === é¡µé¢è®¾ç½® ===
st.set_page_config(page_title="ç¾è‚¡AIåˆ†æå¸ˆ", page_icon="ğŸ“ˆ")
st.title("ğŸ“ˆ ç¾è‚¡AIåˆ†æå¸ˆ")
st.caption("Powered by Google Gemini 2.5 & Yahoo Finance")

# === ä¾§è¾¹æ ï¼šAPI Key é…ç½® ===
# è¿™æ ·ä½ å°±ä¸ç”¨æŠŠ Key å†™æ­»åœ¨ä»£ç é‡Œï¼Œé˜²æ­¢æ³„éœ²
api_key = st.sidebar.text_input("è¾“å…¥ Google API Key", type="password")

# === æ ¸å¿ƒé€»è¾‘ ===
WATCHLIST = {
    # --- ğŸ‡¯ğŸ‡µ æ—¥æœ¬ä¸æ±‡ç‡ (æµåŠ¨æ€§æºå¤´) ---
    "JPY=X": ["ç¾å…ƒå…‘æ—¥å…ƒ", "USD JPY exchange rate carry trade"], 
    "^N225": ["æ—¥ç»225", "Nikkei 225 stock market"],
    
    # --- ğŸ‡ºğŸ‡¸ å®è§‚ä¸é¿é™© (åœ°ç¼˜/é€šèƒ€) ---
    "^TNX":  ["10å¹´æœŸç¾å€º", "US 10 year treasury yield"], 
    "DX-Y.NYB": ["ç¾å…ƒæŒ‡æ•°", "US Dollar index"],
    "^VXN":  ["çº³æŒ‡ææ…ŒæŒ‡æ•°", "Nasdaq Volatility Index"],
    "GC=F":  ["é»„é‡‘ (åœ°ç¼˜é¿é™©)", "Gold price investing"], 
    "CL=F":  ["åŸæ²¹ (é€šèƒ€/ä¸­ä¸œ)", "Crude oil price energy"], 

    # --- ğŸ¤– ç§‘æŠ€ä¸ƒå·¨å¤´ (Mag 7) ---
    "NVDA":  ["è‹±ä¼Ÿè¾¾", "Nvidia stock news"],
    "AAPL":  ["è‹¹æœ", "Apple Inc stock news"],
    "MSFT":  ["å¾®è½¯", "Microsoft stock AI"],
    "TSLA":  ["ç‰¹æ–¯æ‹‰", "Tesla stock news"],
    "AMZN":  ["äºšé©¬é€Š", "Amazon stock news"],
    "META":  ["Meta", "Meta Platforms news"],
    "GOOGL": ["è°·æ­Œ", "Alphabet Google stock"],
    
    # --- âš™ï¸ å…³é”®åŠå¯¼ä½“ ---
    "TSM":   ["å°ç§¯ç”µ", "TSMC stock news"],
}

SPECIAL_TOPICS = [
    "Bank of Japan Governor Ueda policy",  # æ—¥æœ¬å¤®è¡Œ
    "US Federal Reserve Powell",           # ç¾è”å‚¨
    "Geopolitical tension Middle East Russia China", # åœ°ç¼˜æ”¿æ²»
    "US China trade war tariffs",          # è´¸æ˜“æˆ˜/å…³ç¨
]

def get_news(query):
    encoded = quote(query)
    url = f"https://news.google.com/rss/search?q={encoded}&hl=en-US&gl=US&ceid=US:en"
    try:
        # ä½¿ç”¨æ›´åˆç†çš„ User-Agent é¿å…æŸäº›ç½‘ç«™çš„é˜»æ­¢
        headers = {'User-Agent': 'Mozilla/5.0'}
        resp = requests.get(url, timeout=7, headers=headers)
        feed = feedparser.parse(resp.content)
        # å¢åŠ è¿”å›æ•°é‡ï¼Œä»¥è·å¾—æ›´å…¨é¢çš„æ¦‚æ‹¬æ•°æ®
        return [{"title": e.title, "link": e.link} for e in feed.entries[:5]]
    except: return []

def run_analysis():
    if not api_key:
        st.error("è¯·å…ˆåœ¨å·¦ä¾§è¾“å…¥ API Key")
        return

    genai.configure(api_key=api_key.strip(), transport='rest')
    model = genai.GenerativeModel('gemini-2.5-pro')
    
    status_text = st.empty()
    progress_bar = st.progress(0)
    
    market_data = ""
    # æ–°å¢ä¸€ä¸ªåˆ—è¡¨ç”¨äºæ”¶é›†æ‰€æœ‰æ–°é—»ï¼Œç”¨äºåç»­çš„æ¦‚æ‹¬
    all_news_titles = [] 
    
    total_steps = len(WATCHLIST) + len(SPECIAL_TOPICS)
    current_step = 0

    # 1. æŠ“å–èµ„äº§æ•°æ®
    for ticker, info in WATCHLIST.items():
        status_text.text(f"æ­£åœ¨æ‰«æ: {info[0]}...")
        try:
            stock = yf.Ticker(ticker)
            # å¢åŠ ä¸€äº›ç­‰å¾…æ—¶é—´ï¼Œé˜²æ­¢ API é¢‘ç‡é™åˆ¶
            time.sleep(0.1) 
            hist = stock.history(period="2d")
            price = f"{hist['Close'].iloc[-1]:.2f}" if len(hist) > 0 else "N/A"
            
            news = get_news(info[1])
            market_data += f"\nã€{info[0]}ã€‘ ä»·æ ¼:{price}\n"
            for n in news:
                market_data += f"   - {n['title']}\n"
                # æ”¶é›†æ–°é—»æ ‡é¢˜
                all_news_titles.append(n['title'])
            
            # åœ¨ç•Œé¢ä¸Šå±•ç¤ºå®æ—¶æ•°æ®å¡ç‰‡
            with st.expander(f"{info[0]} ({price})", expanded=False):
                for n in news:
                    st.write(f"- [{n['title']}]({n['link']})")

        except Exception as e:
            # st.error(f"Error fetching data for {info[0]}: {e}") # Debugging
            pass
        
        current_step += 1
        progress_bar.progress(current_step / total_steps)

    # 2. æŠ“å–è¯é¢˜
    for topic in SPECIAL_TOPICS:
        status_text.text(f"æ­£åœ¨è¿½è¸ª: {topic}...")
        news = get_news(topic)
        if news:
            market_data += f"\nã€è¯é¢˜: {topic}ã€‘\n"
            for n in news:
                market_data += f"   - {n['title']}\n"
                # æ”¶é›†æ–°é—»æ ‡é¢˜
                all_news_titles.append(n['title'])

        current_step += 1
        progress_bar.progress(current_step / total_steps)

    status_text.text("ğŸ¤– AI æ­£åœ¨æ’°å†™æ·±åº¦æŠ¥å‘Š...")
    
    # 3. AI åˆ†æ - é‡ç‚¹ä¿®æ”¹ Prompt
    
    # å°†æ”¶é›†åˆ°çš„æ‰€æœ‰æ–°é—»æ ‡é¢˜å»é‡å¹¶æ•´ç†æˆä¸€ä¸ªå­—ç¬¦ä¸²ï¼Œä¾›æ¨¡å‹æ¦‚æ‹¬ä½¿ç”¨
    unique_news_titles = "\n".join(list(set(all_news_titles)))
    
    prompt = f"""
    è§’è‰²ï¼šå…¨çƒå®è§‚å¯¹å†²åŸºé‡‘ç­–ç•¥å¸ˆã€‚
    ä»»åŠ¡ï¼šåŸºäºä»¥ä¸‹ã€å¸‚åœºæ•°æ®ã€‘å’Œã€åŸå§‹æ–°é—»æ ‡é¢˜ã€‘å†™ä¸€ä»½ã€ç¾è‚¡å®æˆ˜å†…å‚ã€‘ã€‚
    
    --- åŸå§‹æ–°é—»æ ‡é¢˜ï¼ˆéœ€å…ˆæ¦‚æ‹¬ä¸ºâ€œæœ¬æ—¥ç„¦ç‚¹æ–°é—»é€Ÿè§ˆâ€æ¿å—ï¼‰---
    {unique_news_titles}
    
    --- å¸‚åœºæ•°æ®ï¼ˆç”¨äºåç»­åˆ†æï¼‰---
    {market_data}
    
    è¦æ±‚ï¼š
    1. **å…¨ä¸­æ–‡**ï¼Œé€»è¾‘ä¸¥å¯†ï¼Œè¯­æ°”ä¸“ä¸šã€‚
    2. **å»é“¾æ¥åŒ–**ã€‚
    3. **å¿…é¡»å…ˆæ¦‚æ‹¬**æ‰€æœ‰ã€åŸå§‹æ–°é—»æ ‡é¢˜ã€‘ä¸ºä¸€ä¸ªå•ç‹¬çš„æ¿å—ï¼š**ğŸ“° æœ¬æ—¥ç„¦ç‚¹æ–°é—»é€Ÿè§ˆ**ã€‚è¿™ä¸ªæ¿å—åº”åˆ—å‡º 5-8 æ¡é‡è¦æ–°é—»ï¼Œå¹¶å¯¹æ¯æ¡æ–°é—»è¿›è¡Œ**ä¸€å¥ç®€è¦çš„ä¸­æ–‡æ¦‚æ‹¬**ã€‚
    
    æœ€ç»ˆæ¿å—ç»“æ„ï¼š
    1. ğŸ“° æœ¬æ—¥ç„¦ç‚¹æ–°é—»é€Ÿè§ˆ (éœ€å¯¹åŸå§‹æ–°é—»æ ‡é¢˜è¿›è¡Œæ¦‚æ‹¬ï¼Œä¸­æ–‡)
    2. ğŸ‡¯ğŸ‡µ æ—¥æœ¬æµåŠ¨æ€§
    3. ğŸŒ åœ°ç¼˜é¿é™©
    4. ğŸ‡ºğŸ‡¸ å®è§‚å‹åŠ›
    5. ğŸ‘‘ ç§‘æŠ€ä¸ƒå·¨å¤´
    6. ğŸ“ äº¤æ˜“ç­–ç•¥(å«ä»“ä½å»ºè®®)
    """
    
    try:
        response = model.generate_content(prompt)
        st.success("åˆ†æå®Œæˆï¼")
        st.markdown("---")
        st.markdown(response.text)
    except Exception as e:
        st.error(f"AI ç”Ÿæˆå¤±è´¥: {e}")

# === æŒ‰é’® ===
if st.button("ğŸš€ å¯åŠ¨å…¨æ™¯é›·è¾¾", type="primary"):
    run_analysis()